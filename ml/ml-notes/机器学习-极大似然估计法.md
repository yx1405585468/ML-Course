[toc]

# 一、什么是极大似然估计

机器学习中，概率模型的训练过程就是**参数估计(Parameter Estimation)**的过程，对于参数估计，统计学界的两个学派分别提供了不同的解决方案：频率主义学派认为参数虽然未知，但却是客观存在的固定值，因此可以通过优化似然函数等准则来确定参数值；贝叶斯学派则认为参数是未观察到的随机变量，其本身也可有分布，因此可假定参数服从一个先验分布，然后基于观测的数据来计算参数的后验分布。**极大似然估计(Maximum LikeliHood Estimation)**源自于频率主义学派，它是一种根据数据采样来估计概率分布参数的经典方法。

# 二、参数训练过程

令$D_c$表示训练集$D$中第$c$类样本组成的集合，假设这些样本是独立同分布的，则参数$θ_c$对于数据集$D_c$的似然是
$$
P\left(D_{c} | \theta_{c}\right)=\prod_{x \in D_{c}} P\left(x | \theta_{c}\right)\tag{1}
$$
对$\theta_c$进行极大似然估计，就是去寻找能最大化似然$P\left(D_{c} | \theta_{c}\right)$的参数值$\hat{\theta_c}$。直观上看，极大似然估计是视图在$\theta_c$上所有可能的取值中，找到一个能使数据出现的“可能性”最大的值。

式(1)中的连乘操作容易造成下溢，通常使用对数似然(log-likelihood)
$$
\begin{aligned} L\left(\theta_{c}\right) &=\log P\left(D_{c} | \theta_{c}\right) \\ &=\sum_{x \in D_{c}} \log P\left(x | \theta_{c}\right) \end{aligned}\tag{2}
$$
此时的参数$\theta_c$的极大似然估计$\hat{\theta_c}$为
$$
\hat{\theta}_{c}=\underset{\theta_{c}}{\arg \max } L\left(\theta_{c}\right)\tag{3}
$$

> 【例 1】假设一个袋子装有白球与红球，比例未知，现在抽取10次（每次抽完都放回，保证事件独立性），假设抽到了7次白球和3次红球，在此数据样本条件下，采用极大似然估计法求解袋子中白球的比例。

【解】设$\theta$为袋子中白球的比例，根据公式(1)可以建立实际情况下的概率
$$
P\left(x_1,x_2,\ldots,x_{10} | \theta\right)=P\left(x_1|\theta\right) \cdot P\left(x_2|\theta\right) \ldots P\left(x_{10}|\theta\right)\tag{4}
$$
对数似然为
$$
L(\theta)=\ln P\left(x_1,x_2,\ldots,x_{10} | \theta\right)=\ln \left[\theta^7(1-\theta)^3\right]\tag{5}
$$
对$\theta$求导数可以得到
$$
L^{\prime}(\theta)=\frac{7}{\theta}-\frac{3}{1-\theta}=0 \Rightarrow \hat{\theta}=0.7 \tag{6}
$$
由此可得，当抽取白球的概率为0.7时，最可能产生10次抽取抽到白球7次的事件。

> 【例 2】假设有一组采样值$(x_1,x_2,\ldots,x_n)$服从正态分布$N(\mu,\sigma^2)$，采用极大似然估计法估计参数，使得产生这个采样值的概率最大。

【解】正态分布的概率为
$$
f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)\tag{7}
$$
则产生采样值$(x_1,x_2,\ldots,x_n)$的概率为
$$
P\left(x_{1}, x_{2}, \ldots, x_{n} | \theta\right)=\left(\frac{1}{\sqrt{2 \pi} \sigma}\right)^{n} \exp \left(-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}(x_i-\mu)^{2}\right) \tag{8}
$$
对上式两边取对数可以得到
$$
L(\theta)=\ln P\left(x_1,x_2,\ldots,x_{n} | \theta\right)=n\ln\frac{1}{\sqrt{2 \pi} \sigma}-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}(x_i-\mu)^{2}\tag{9}
$$
$\theta$有两个参数$\mu,\sigma^2$，对$\mu$求偏导数得
$$
\frac{\partial L(\theta)}{\partial \mu}=-\frac{1}{\sigma_{2}}\sum_{i=1}^{n}(\mu-x_i)=0\tag{10}
$$
可以得到
$$
\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n}x_i\tag{11}
$$
对$\sigma^2$求偏导数得
$$
\frac{\partial L(\theta)}{\partial \sigma^{2}}=-n+\frac{1}{\sigma^{2}} \sum_{i=1}^{n}(x_i-\hat{\mu})^{2}=0\tag{12}
$$
可以得到
$$
\hat{\sigma^{2}}=\frac{1}{n}\sum_{i=1}^{n}(x_i-\hat{\mu})^{2}\tag{13}
$$

# 三、参考

[1] 周志华. 机器学习,  清华大学出版社

[2] [简书博客](https://www.jianshu.com/p/f1d3906e4a3e)